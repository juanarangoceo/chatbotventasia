import time
import json
import openai
from modules.producto_helper import cargar_especificaciones_producto
from dotenv import load_dotenv
import os

# Cargar variables de entorno
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# Instanciar cliente OpenAI
client = openai.Client(api_key=api_key)

# Almacenar el estado de los clientes
usuarios = {}

# Respuestas predefinidas clave
PREGUNTAS_CLAVE = {
    "leche": "SÃ­, la *Cafetera Espresso Pro* tiene un tubo de vapor de acero inoxidable para crear espuma de leche perfecta. ğŸ¥›â˜•",
    "precio": "El precio de la *Cafetera Espresso Pro* es *399,900 COP* ğŸ’° con *envÃ­o gratis a toda Colombia* ğŸšš.",
    "garantÃ­a": "La *Cafetera Espresso Pro* tiene garantÃ­a de *6 meses* por defectos de fÃ¡brica. ğŸ”§ğŸ“¦",
}

def obtener_respuesta(mensaje, cliente_id):
    """Gestiona la conversaciÃ³n y responde de forma inteligente."""

    time.sleep(2)  # Simula un tiempo de respuesta
    mensaje = mensaje.lower().strip()

    # ğŸ”¹ Si el usuario es nuevo, iniciar la conversaciÃ³n con el saludo correcto
    if cliente_id not in usuarios:
        usuarios[cliente_id] = {"estado": "preguntar_ciudad"}
        return (
            "Â¡Hola! â˜• Soy Juan, tu asesor de cafÃ© profesional. "
            "Estoy aquÃ­ para ayudarte con la *Cafetera Espresso Pro*. ğŸ™Œ\n\n"
            "âœï¸ *Â¿Desde quÃ© ciudad nos escribes?* ğŸ™ï¸"
        )

    # ğŸ”¹ Si estÃ¡ en la fase de preguntar la ciudad, guardar y avanzar
    if usuarios[cliente_id]["estado"] == "preguntar_ciudad":
        usuarios[cliente_id]["ciudad"] = mensaje.title()
        usuarios[cliente_id]["estado"] = "confirmar_interes"
        return (
            f"Â¡Gracias! Enviamos a {mensaje.title()} con *pago contra entrega* ğŸš›.\n\n"
            "Â¿Te gustarÃ­a conocer mÃ¡s sobre nuestra *Cafetera Espresso Pro*? â˜•"
        )

    # ğŸ”¹ Si el usuario confirma interÃ©s, explicar beneficios
    if usuarios[cliente_id]["estado"] == "confirmar_interes" and mensaje in ["sÃ­", "si", "claro", "me gustarÃ­a saber mÃ¡s"]:
        usuarios[cliente_id]["estado"] = "explicar_beneficios"
        return (
            "Nuestra *Cafetera Espresso Pro* â˜• tiene:\n"
            "- PresiÃ³n de 15 bares para un espresso perfecto\n"
            "- Espumador de leche integrado ğŸ¥›\n"
            "- PreparaciÃ³n automÃ¡tica con un solo toque ğŸ”˜\n\n"
            "ğŸ‘‰ *Â¿Prefieres cafÃ© espresso o cappuccino?*"
        )

    # ğŸ”¹ Si el usuario pregunta por caracterÃ­sticas del producto
    if any(palabra in mensaje for palabra in ["caracterÃ­sticas", "detalles", "quÃ© incluye"]):
        producto = cargar_especificaciones_producto()
        if "error" in producto:
            return "âš ï¸ Lo siento, hubo un error al cargar la informaciÃ³n del producto."

        respuesta = f"ğŸ“¦ *{producto['nombre']}* â˜•\n{producto['descripcion']}\n\n"
        respuesta += "ğŸ“Œ *CaracterÃ­sticas:* \n"
        respuesta += "\n".join([f"- {c}" for c in producto["caracteristicas"]])
        respuesta += f"\nğŸ’° *Precio:* {producto['precio']}\nğŸšš {producto['envio']}\n\n"
        respuesta += "ğŸ‘‰ *Â¿Quieres que te ayude a procesar tu pedido?* ğŸ“¦"

        return respuesta

    # ğŸ”¹ Si la pregunta coincide con una de las preguntas clave, responder con informaciÃ³n relevante
    for clave, respuesta in PREGUNTAS_CLAVE.items():
        if clave in mensaje:
            return respuesta

    # ğŸ”¹ Si el mensaje no encaja con ninguna respuesta, usar OpenAI para generar una respuesta natural
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "system", "content": "Responde como un vendedor experto en cafeteras de forma clara y natural."},
                      {"role": "user", "content": mensaje}],
            temperature=0.7,
            max_tokens=200
        )
        return response.choices[0].message.content.strip()

    except openai.APIError:
        return "âš ï¸ Lo siento, hubo un problema con el servicio de OpenAI. IntÃ©ntalo mÃ¡s tarde."

