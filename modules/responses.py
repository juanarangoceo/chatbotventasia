import time
import json
import openai
from modules.producto_helper import cargar_especificaciones_producto
from dotenv import load_dotenv
import os

# Cargar variables de entorno
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# Instanciar cliente OpenAI
client = openai.Client(api_key=api_key)

# Almacenar el estado de los clientes
usuarios = {}

# Respuestas predefinidas clave
PREGUNTAS_CLAVE = {
    "leche": "SÃ­, la *Cafetera Espresso Pro* tiene un espumador de leche ğŸ¥› para texturas perfectas. Â¿Quieres que te ayude con tu pedido? ğŸ“¦",
    "precio": "La *Cafetera Espresso Pro* cuesta *399,900 COP* ğŸ’° con *envÃ­o gratis* ğŸšš. Â¿Deseas que la enviemos a tu domicilio? ğŸ¡",
    "garantÃ­a": "Tiene *6 meses de garantÃ­a* ğŸ”§ por defectos de fÃ¡brica. Es un equipo duradero y confiable. Â¿Te gustarÃ­a ordenar la tuya hoy? â˜•",
}

def obtener_respuesta(mensaje, cliente_id):
    """Gestiona la conversaciÃ³n asegurando que el chatbot siga vendiendo siempre."""

    time.sleep(2)  # Simula un tiempo de respuesta
    mensaje = mensaje.lower().strip()

    # ğŸ”¹ Si el usuario es nuevo, iniciar con saludo y pregunta de ciudad
    if cliente_id not in usuarios:
        usuarios[cliente_id] = {"estado": "preguntar_ciudad"}
        return (
            "Â¡Hola! â˜• Soy Juan, experto en cafÃ©. Te ayudarÃ© con la *Cafetera Espresso Pro*. ğŸ™Œ\n\n"
            "âœï¸ *Â¿Desde quÃ© ciudad nos escribes?* ğŸ™ï¸"
        )

    # ğŸ”¹ Guardar ciudad y avanzar en el flujo
    if usuarios[cliente_id]["estado"] == "preguntar_ciudad":
        usuarios[cliente_id]["ciudad"] = mensaje.title()
        usuarios[cliente_id]["estado"] = "confirmar_interes"
        return (
            f"Â¡Genial! Enviamos a {mensaje.title()} con *pago contra entrega* ğŸš›.\n\n"
            "ğŸ‘‰ *Â¿Te gustarÃ­a conocer mÃ¡s sobre la Cafetera Espresso Pro?*"
        )

    # ğŸ”¹ Si el usuario confirma interÃ©s, explicar beneficios en una respuesta corta
    if usuarios[cliente_id]["estado"] == "confirmar_interes" and mensaje in ["sÃ­", "si", "claro", "me gustarÃ­a saber mÃ¡s"]:
        usuarios[cliente_id]["estado"] = "explicar_beneficios"
        return (
            "ğŸ”¹ La *Cafetera Espresso Pro* tiene:\n"
            "- *15 bares de presiÃ³n* para espressos perfectos â˜•\n"
            "- *Espumador de leche* ğŸ¥› para capuchinos cremosos\n"
            "- *FÃ¡cil de usar* con pantalla tÃ¡ctil\n\n"
            "âœ… *Â¿Te gustarÃ­a recibirla con pago contra entrega?*"
        )

    # ğŸ”¹ Si el usuario pregunta por caracterÃ­sticas del producto
    if any(palabra in mensaje for palabra in ["caracterÃ­sticas", "detalles", "quÃ© incluye"]):
        producto = cargar_especificaciones_producto()
        if "error" in producto:
            return "âš ï¸ Lo siento, hubo un error al cargar la informaciÃ³n del producto."

        respuesta = (
            f"ğŸ“¦ *{producto['nombre']}* â˜•\n{producto['descripcion']}\n\n"
            "ğŸ“Œ *CaracterÃ­sticas principales:* \n"
            + "\n".join([f"- {c}" for c in producto["caracteristicas"]])
            + f"\nğŸ’° *Precio:* {producto['precio']}\nğŸšš {producto['envio']}\n\n"
            "ğŸ“¦ *Â¿Quieres que la enviemos hoy mismo?* ğŸš›"
        )

        return respuesta

    # ğŸ”¹ Si la pregunta coincide con una de las preguntas clave, responder con informaciÃ³n relevante y reforzar la venta
    for clave, respuesta in PREGUNTAS_CLAVE.items():
        if clave in mensaje:
            return respuesta

    # ğŸ”¹ Si el mensaje no encaja con ninguna respuesta, usar OpenAI con un prompt mÃ¡s controlado
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": (
                    "Eres Juan, un asesor de ventas especializado en la *Cafetera Espresso Pro*. "
                    "Tu Ãºnico objetivo es vender este producto. Responde siempre con respuestas cortas, "
                    "claras y enfocadas en cerrar la venta. No menciones otros productos. "
                    "Si te hacen una pregunta, respÃ³ndela y luego lleva la conversaciÃ³n de vuelta a la compra."
                )},
                {"role": "user", "content": mensaje}
            ],
            temperature=0.3,  # Reducir creatividad para respuestas mÃ¡s predecibles
            max_tokens=150
        )
        return response.choices[0].message.content.strip() + "\n\nğŸ“¦ *Â¿Quieres que te ayude a realizar tu pedido?* ğŸš›"

    except openai.APIError:
        return "âš ï¸ Lo siento, hubo un problema con el servicio de OpenAI. IntÃ©ntalo mÃ¡s tarde."

